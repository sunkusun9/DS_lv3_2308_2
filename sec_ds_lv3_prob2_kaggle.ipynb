{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aa73290",
   "metadata": {},
   "source": [
    "## 문제 6\n",
    "\n",
    "**Kaggle 형** train_prob.csv로 문제 target을 예측하는 모델을 만들고, \n",
    "\n",
    "test_prob.csv에 대한 target 예측하여 다음과 같은 형식의 answer6.csv를 만들어라.\n",
    "\n",
    "id, target\n",
    "\n",
    "0, 6.9\n",
    "\n",
    "5, 7.8\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "**평가지표**\n",
    "\n",
    "$RMSE(Y, \\hat{Y}) = \\sqrt{\\frac{1}{n}\\sum^{n}_{i=1}(y_i-\\hat{y_i})^2}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8453bdf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc9d4d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_prob.csv', index_col='id')\n",
    "df_test = pd.read_csv('test_prob.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c3df24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat3 {'B': 'C'} [83634, 147361, 9005]\n",
      "cat4 {'A': 'B', 'D': 'B'} [239397, 603]\n",
      "cat6 {'D': 'A', 'E': 'B', 'G': 'C', 'H': 'B', 'I': 'A'} [234203, 5145, 652]\n",
      "cat7 {'A': 'B', 'C': 'B', 'F': 'D', 'I': 'B'} [4606, 19784, 214027, 1583]\n",
      "cat8 {'B': 'G', 'F': 'E'} [30338, 96743, 2953, 76085, 33881]\n",
      "cat9 {'C': 'H', 'D': 'B', 'E': 'L'} [10678, 2846, 85944, 8320, 19987, 40070, 5501, 16743, 33793, 7819, 3331, 4968]\n"
     ]
    }
   ],
   "source": [
    "# 반복문을 구성하여 처리해 봅니다.\n",
    "\n",
    "# 처리 내용을 정의합니다, (대상 변수명, 치환할 내용, 치환후 수준별 카운트)\n",
    "repl_list = [\n",
    "    ('cat3', {'B': 'C'}, [83634, 147361, 9005]), \n",
    "    ('cat4', {'A': 'B', 'D': 'B'}, [239397, 603]),\n",
    "    ('cat6', {'D': 'A', 'E': 'B', 'G': 'C', 'H': 'B', 'I': 'A'}, [234203, 5145, 652]),\n",
    "    ('cat7', {'A': 'B', 'C': 'B', 'F': 'D', 'I': 'B'}, [4606, 19784, 214027, 1583]),\n",
    "    ('cat8', {'B': 'G', 'F': 'E'}, [30338, 96743, 2953, 76085, 33881]),\n",
    "    ('cat9', {'C': 'H', 'D': 'B', 'E': 'L'}, [10678, 2846, 85944, 8320, 19987, 40070, 5501, 16743, 33793, 7819, 3331, 4968])\n",
    "]\n",
    "\n",
    "for c, d, cnt in repl_list:\n",
    "    print(c, d, cnt)\n",
    "    s_repl = df_train[c].replace(d) # 치환을 합니다. (아직 반영은 하지 않습니다.)\n",
    "    if not (s_repl.value_counts().sort_index() == cnt).all(): # 치환후 카운트를 체크합니다.\n",
    "        print(\"Error\", c, d, cnt, s_repl.value_counts().sort_index()) # 에러 내용을 출력합니다.\n",
    "        break\n",
    "    df_train[c] = s_repl # 치환한 결과를 반영합니다.\n",
    "    df_test[c] = df_test[c].replace(d) # 테스트에 대해서도 반영합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c31944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문제 4번을 활용하기 위해 반듭니다.\n",
    "df_train['targetA'] = df_train['target'] <= 7.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84a62476",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [i for i in np.arange(0, 1.01, 0.01)]\n",
    "# 나머지 변수에 대해서도 해당 파생 변수를 만들어 줍니다.\n",
    "for i in range(0, 14):\n",
    "    col = 'cont{}'.format(i)\n",
    "    qt = df_train[col].quantile(q)\n",
    "    qt.iloc[[0, -1]] = [-np.inf, np.inf]\n",
    "    q_cut = pd.cut(df_train[col], bins=qt)\n",
    "    q_mean = df_train.groupby(q_cut)['target'].mean()\n",
    "    df_train[col + '_q'] = q_cut.map(q_mean).astype('float')\n",
    "    df_test[col + '_q'] = pd.cut(df_test[col], bins=qt).map(q_mean).astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9011b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "mu_A, s_A = 6.769, 0.616\n",
    "mu_B, s_B = 8.123, 0.527\n",
    "\n",
    "df_train_clf = df_train.assign(\n",
    "    # 귀무가설 : target은 A입니다, 대립가설: target은 B입니다.\n",
    "    prob_A = 1 - norm.cdf(df_train['target'], loc=mu_A, scale=s_A),\n",
    "    # 귀무가설 : target은 B입니다, 대립가설: target은 A입니다.\n",
    "    prob_B = norm.cdf(df_train['target'], loc=mu_B, scale=s_B)\n",
    ")\n",
    "df_train_clf = df_train_clf.query('prob_B < 0.01 or prob_A < 0.01').copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c413f33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, KFold \n",
    "\n",
    "cv = KFold(n_splits=5, random_state=123)\n",
    "neg_rmse = make_scorer(lambda y, y_hat: -mean_squared_error(y, y_hat) ** 0.5)\n",
    "df_ans = pd.read_csv('test_prob_ans.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f83e2098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=None,\n",
       "                                                                drop=None,\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                n_values=None,\n",
       "                                                                sparse=True),\n",
       "                                                  ['cat0', 'cat1', 'cat2',\n",
       "                                                   'cat3', 'cat4', 'cat5'...\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bytree=0.25,\n",
       "                               gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "                               max_depth=2, min_child_weight=1, missing=None,\n",
       "                               n_estimators=500, n_jobs=1, nthread=None,\n",
       "                               objective='binary:logistic', random_state=123,\n",
       "                               reg_alpha=0.1, reg_lambda=0.1,\n",
       "                               scale_pos_weight=1, seed=None, silent=True,\n",
       "                               subsample=1))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제 4번 모델을 만듭니다. targetA일 확률을 활용할 예정입니다.\n",
    "import xgboost as xgb\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}'.format(i) for i in range(14)])\n",
    "])\n",
    "X_xgb = ['cont{}'.format(i) for i in range(14)] + ['cat{}'.format(i) for i in range(10)]\n",
    "clf_xgb = make_pipeline(\n",
    "    ct,\n",
    "    xgb.XGBClassifier(\n",
    "        max_depth = 2, # 트리의 최대 깊이 2\n",
    "        reg_alpha = 0.1, # L1 규제 0.1\n",
    "        reg_lambda = 0.1, # L2 규제 0.1\n",
    "        colsample_bytree=0.25, # 트리 당 컬럼 샘플링 비율 0.25\n",
    "        n_estimators=500, # 트리의 수 500\n",
    "        random_state=123, # random_state 123\n",
    "    )\n",
    ")\n",
    "\n",
    "X_xgb = ['cat{}'.format(i) for i in range(10)] + ['cont{}'.format(i) for i in range(14)]\n",
    "clf_xgb.fit(df_train_clf[X_xgb], df_train_clf['targetA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bbe1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['targetA_prob'] = clf_xgb.predict_proba(df_train[X_xgb])[:, 1]\n",
    "df_test['targetA_prob'] = clf_xgb.predict_proba(df_test[X_xgb])[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4370e257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.85896269, -0.86640703, -0.8608483 , -0.86374819, -0.866262  ]),\n",
       " -0.8632456423386845)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline 모델을 만들어 봅니다.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(drop='first'), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}'.format(i) for i in range(14)])\n",
    "])\n",
    "X_lr = ['cat{}'.format(i) for i in range(10)] + ['cont{}'.format(i) for i in range(14)]\n",
    "reg_lr = make_pipeline(ct, LinearRegression())\n",
    "scores_ = cross_val_score(reg_lr, df_train[X_lr], df_train['target'], cv=cv, scoring=neg_rmse)\n",
    "scores_, np.mean(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "709f9c45",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('ohe',\n",
       "                                                  OneHotEncoder(categorical_features=None,\n",
       "                                                                categories=None,\n",
       "                                                                drop='first',\n",
       "                                                                dtype=<class 'numpy.float64'>,\n",
       "                                                                handle_unknown='error',\n",
       "                                                                n_values=None,\n",
       "                                                                sparse=True),\n",
       "                                                  ['cat0', 'cat1', 'cat2',\n",
       "                                                   'cat3', 'cat4', 'cat5',\n",
       "                                                   'cat6', 'cat7', 'cat8',\n",
       "                                                   'cat9']),\n",
       "                                                 ('pt', 'passthrough',\n",
       "                                                  ['cont0', 'cont1', 'cont2',\n",
       "                                                   'cont3', 'cont4', 'cont5',\n",
       "                                                   'cont6', 'cont7', 'cont8',\n",
       "                                                   'cont9', 'cont10', 'cont11',\n",
       "                                                   'cont12', 'cont13'])],\n",
       "                                   verbose=False)),\n",
       "                ('linearregression',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline 모델을 전체 학습셋에 대해 학습을 시킵니다.\n",
    "reg_lr.fit(df_train[X_lr], df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5266e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일을 만듭니다.\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'id': df_train.index.values,\n",
    "        'target': reg_lr.predict(df_train[X_lr])\n",
    "    }\n",
    ").to_csv('answer6.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50def4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8657267201878256"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 채점을 합니다.\n",
    "mean_squared_error(df_ans['target'], reg_lr.predict(df_test[X_lr])) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd3339fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.86322076, -0.87123946, -0.86549819, -0.86797077, -0.87060344]),\n",
       " -0.867706523827423)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# OneHotEncoder가 좋은 예를 보여드리기 위해 만들어봅니다.\n",
    "# Sparse Matrix 형태로 output을 뽑아 메모리 효율적인 모델을 만듭니다.\n",
    "# TruncatedSVD PCA에서 mean centering을 제외한 모델로 \n",
    "# Sparse Matrix에 대하여 연산 효율성이 높은 모델입니다.\n",
    "# 이를 통해 차원을 줄여 봅니다.\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', make_pipeline(OneHotEncoder(drop='first'), TruncatedSVD(n_components=7)), \n",
    "                     ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}'.format(i) for i in range(14)])\n",
    "])\n",
    "\n",
    "X_lr = ['cat{}'.format(i) for i in range(10)] + ['cont{}'.format(i) for i in range(14)]\n",
    "reg_lr = make_pipeline(\n",
    "    ct, \n",
    "    LinearRegression()\n",
    ")\n",
    "score_ = cross_val_score(reg_lr, df_train[X_lr], df_train['target'], scoring=neg_rmse, cv=cv)\n",
    "score_, np.mean(score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b31eee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.8402359 , -0.84609288, -0.84104535, -0.84219744, -0.84800272]),\n",
       " -0.8435148589687671)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targetA_prob를 입력 변수에 추가해봅니다.\n",
    "from sklearn.linear_model import LinearRegression\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(drop='first'), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}'.format(i) for i in range(14)] + ['targetA_prob'])\n",
    "])\n",
    "X_lr = ['cat{}'.format(i) for i in range(10)] + ['cont{}'.format(i) for i in range(14)] + ['targetA_prob']\n",
    "reg_lr = make_pipeline(ct, LinearRegression())\n",
    "scores_ = cross_val_score(reg_lr, df_train[X_lr], df_train['target'], cv=cv, scoring=neg_rmse)\n",
    "scores_, np.mean(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d03a96e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8493184210459027"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targetA_prob 추가 모델에 대한 채점입니다.\n",
    "reg_lr.fit(df_train[X_lr], df_train['target'])\n",
    "mean_squared_error(df_ans['target'], reg_lr.predict(df_test[X_lr])) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "361d6774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.8436393559001433,\n",
       " [-0.8405098833949913,\n",
       "  -0.8462240557462019,\n",
       "  -0.841351783962399,\n",
       "  -0.8421568739266677,\n",
       "  -0.847954182470457])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quantile -> mean 파생변수의 Leak을 없앤 버젼의 교차 검증을 들고 왔습니다.\n",
    "# 실제 시험에서 이런 루틴을 구현하기에 시간이 꽤 필요합니다.\n",
    "# 제대로 Leak 없이 검증해본다면, 이렇게 해볼수 있다고 참고만 하시면됩니다.\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(drop='first'), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}_q'.format(i) for i in range(14)] + ['targetA_prob'])\n",
    "])\n",
    "X_rd = ['cat{}'.format(i) for i in range(10)] + ['cont{}_q'.format(i) for i in range(14)] + ['targetA_prob']\n",
    "reg_rd= make_pipeline(\n",
    "    ct, \n",
    "    Ridge(alpha=0.1)\n",
    ")\n",
    "q = [i for i in np.arange(0, 1.01, 0.01)]\n",
    "score_ = []\n",
    "for train_idx, test_idx in cv.split(df_train):\n",
    "    df_cv_train, df_cv_test = df_train.iloc[train_idx].copy(), df_train.iloc[test_idx].copy()\n",
    "    # 검증셋에서 train으로 파생변수를 만들고\n",
    "    # 검증셋의 test(겹외셋)에 검증셋의 train으로 만든 통계값(mean)을 반영합니다.\n",
    "    for i in range(0, 14):\n",
    "        col = 'cont{}'.format(i)\n",
    "        qt = df_cv_train[col].quantile(q)\n",
    "        qt.iloc[[0, -1]] = [-np.inf, np.inf]\n",
    "        q_cut = pd.cut(df_cv_train[col], bins=qt)\n",
    "        q_mean = df_cv_train.groupby(q_cut)['target'].mean()\n",
    "        df_cv_train[col + '_q'] = q_cut.map(q_mean).astype('float')\n",
    "        df_cv_test[col + '_q'] = pd.cut(df_cv_test[col], bins=qt).map(q_mean).astype('float')\n",
    "    reg_rd.fit(df_cv_train[X_rd], df_cv_train['target'])\n",
    "    score_.append(-(mean_squared_error(df_cv_test['target'], reg_rd.predict(df_cv_test[X_rd])) ** 0.5))\n",
    "np.mean(score_), score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f79af9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847877050449364"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean encoding 속성 처리 모델입니다. & 채점결과 입니다.\n",
    "reg_rd.fit(df_train[X_rd], df_train['target'])\n",
    "mean_squared_error(df_ans['target'], reg_rd.predict(df_test[X_rd])) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2fdc91d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.8429296162391553"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 문제5에서 최적의 모델을 가져옵니다.\n",
    "# 5~10 정도 실행시간이 필요합니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}'.format(i) for i in range(14)] + ['targetA_prob'])\n",
    "])\n",
    "X_xgb = ['cat{}'.format(i) for i in range(10)] + ['cont{}'.format(i) for i in range(14)] + ['targetA_prob']\n",
    "reg_xgb = make_pipeline(\n",
    "    ct,\n",
    "    xgb.XGBRegressor(\n",
    "        colsample_bytree=0.25, \n",
    "        n_estimators=500,\n",
    "        max_depth=2, # 트리의 최대 깊이는 2, \n",
    "        random_state=123 # 랜덤 시드는 123\n",
    "    )\n",
    ")\n",
    "score_ = cross_val_score(reg_xgb, df_train[X_xgb], df_train['target'], scoring=neg_rmse, cv=cv)\n",
    "np.mean(score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56ac5ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8473356006330207"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 train set으로 학습시킵니다. & 채점 결과입니다.\n",
    "reg_xgb.fit(df_train[X_xgb], df_train['target'])\n",
    "mean_squared_error(df_ans['target'], reg_xgb.predict(df_test[X_xgb])) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dbcb7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블할 모델들을 모아 왔습니다.\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "# Baseline에 입력변수로 targetA_prob\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(drop='first'), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}'.format(i) for i in range(14)] + ['targetA_prob'])\n",
    "])\n",
    "\n",
    "X_lr = ['cat{}'.format(i) for i in range(10)] + ['cont{}'.format(i) for i in range(14)] + ['targetA_prob']\n",
    "reg_lr_2 = make_pipeline(\n",
    "    ct, \n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "# mean encoding을 추가한 모델입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(drop='first'), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}_q'.format(i) for i in range(14)] + ['targetA_prob'])\n",
    "])\n",
    "X_rd = ['cat{}'.format(i) for i in range(10)] + ['cont{}_q'.format(i) for i in range(14)] + ['targetA_prob']\n",
    "reg_rd= make_pipeline(\n",
    "    ct, \n",
    "    Ridge(alpha=0.1)\n",
    ")\n",
    "\n",
    "# xgboost 모델입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(), ['cat{}'.format(i) for i in range(10)]),\n",
    "    ('pt', 'passthrough', ['cont{}'.format(i) for i in range(14)] + ['targetA_prob'])\n",
    "])\n",
    "X_xgb = ['cat{}'.format(i) for i in range(10)] + ['cont{}'.format(i) for i in range(14)] + ['targetA_prob']\n",
    "reg_xgb = make_pipeline(\n",
    "    ct,\n",
    "    xgb.XGBRegressor(\n",
    "        colsample_bytree=0.25, # 트리 생성시 컬럼샘플링 비율: 0.25\n",
    "        n_estimators=500, # 트리의 수: 500\n",
    "        max_depth=2, # 트리의 최대 깊이는 2, \n",
    "        random_state=123 # 랜덤 시드는 123\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "168fd9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.8422019061048704,\n",
       " array([-0.83891828, -0.84479408, -0.8398083 , -0.84088908, -0.8465998 ]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Voting 앙상블 기법을 활용하여 앙상블 모델을 만듭니다.\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "reg_vt = VotingRegressor([\n",
    "    ('lr_1', reg_lr_2),\n",
    "    ('lr_2', reg_rd),\n",
    "    ('xgb', reg_xgb),\n",
    "])\n",
    "X_vt = ['cat{}'.format(i) for i in range(10)] + ['cont{}'.format(i) for i in range(14)] \\\n",
    "    + ['cont{}_q'.format(i) for i in range(14)] + ['targetA_prob']\n",
    "score_ = cross_val_score(reg_vt, df_train[X_vt], df_train['target'], scoring=neg_rmse, cv=cv)\n",
    "np.mean(score_), score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dc5989c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingRegressor(estimators=[('lr_1',\n",
       "                             Pipeline(memory=None,\n",
       "                                      steps=[('columntransformer',\n",
       "                                              ColumnTransformer(n_jobs=None,\n",
       "                                                                remainder='drop',\n",
       "                                                                sparse_threshold=0.3,\n",
       "                                                                transformer_weights=None,\n",
       "                                                                transformers=[('ohe',\n",
       "                                                                               OneHotEncoder(categorical_features=None,\n",
       "                                                                                             categories=None,\n",
       "                                                                                             drop='first',\n",
       "                                                                                             dtype=<class 'numpy.float64'>,\n",
       "                                                                                             handle_unknown='error',\n",
       "                                                                                             n_values=None,\n",
       "                                                                                             sparse=True),\n",
       "                                                                               ['c...\n",
       "                                              XGBRegressor(base_score=0.5,\n",
       "                                                           booster='gbtree',\n",
       "                                                           colsample_bylevel=1,\n",
       "                                                           colsample_bytree=0.25,\n",
       "                                                           gamma=0,\n",
       "                                                           learning_rate=0.1,\n",
       "                                                           max_delta_step=0,\n",
       "                                                           max_depth=2,\n",
       "                                                           min_child_weight=1,\n",
       "                                                           missing=None,\n",
       "                                                           n_estimators=500,\n",
       "                                                           n_jobs=1,\n",
       "                                                           nthread=None,\n",
       "                                                           objective='reg:linear',\n",
       "                                                           random_state=123,\n",
       "                                                           reg_alpha=0,\n",
       "                                                           reg_lambda=1,\n",
       "                                                           scale_pos_weight=1,\n",
       "                                                           seed=None,\n",
       "                                                           silent=True,\n",
       "                                                           subsample=1))],\n",
       "                                      verbose=False))],\n",
       "                n_jobs=None, weights=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_vt.fit(df_train[X_vt], df_train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1d62e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 제출파일입니다.\n",
    "pd.DataFrame(\n",
    "    reg_vt.predict(df_test[X_vt]),\n",
    "    index=df_test.index, columns=['target']\n",
    ").to_csv('answer6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6841b337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8475964306877575"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(df_ans['target'], reg_vt.predict(df_test[X_vt])) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c94aa",
   "metadata": {},
   "source": [
    "3일 간의 실습 강의를 포함하여 총 8일간 강의 들으시느라 고생 많으셨습니다.\n",
    "\n",
    "궁금하신점 있으시면 연락주세요. \n",
    "\n",
    "좋은 소식이 들려 오기를 눈 빼꼼 뜨고 기다리겠스니다.\n",
    "\n",
    "**멀티캠퍼스 강선구(sunku0316.kang@multicampus.com) 올림**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80493ba7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
