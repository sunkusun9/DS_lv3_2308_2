{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "765c0422",
   "metadata": {},
   "source": [
    "# 문제 6\n",
    "\n",
    "[Kaggle 형] train_prob.csv로 failure 예측하는 모델을 만들고, \n",
    "\n",
    "test_prob.csv에 대한 failure가 1일 확률 예측하여 다음과 같은 형식의 answer6.csv를 만들어라. \n",
    "\n",
    "측정 지표는 AUC(area under of ROC curve)이다. id 는 테스트 케이스의 id 이고, failure에는 failure가 1이 될 확률이다.\n",
    "\n",
    "id,failure\n",
    "\n",
    "16115, 0.1\n",
    "\n",
    "16116, 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "422cead3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)]\n",
      "pandas 0.25.1\n",
      "numpy 1.18.5\n",
      "sklearn 0.21.3\n",
      "scipy 1.5.2\n",
      "mlxtend 0.15.0.0\n",
      "statsmodels 0.11.1\n"
     ]
    }
   ],
   "source": [
    "# 실행 환경 확인\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import scipy\n",
    "import statsmodels\n",
    "import mlxtend\n",
    "import sys\n",
    "\n",
    "print(sys.version)\n",
    "for i in [pd, np, sklearn, scipy, mlxtend, statsmodels]:\n",
    "    print(i.__name__, i.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e02fca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_prob.csv', index_col='id')\n",
    "df_test = pd.read_csv('test_prob.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0e632eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 처리하기 전에,\n",
    "# 결측 여부가 failure를 예측하는데, 유용할 만하다고 도출된\n",
    "# measurement_3, measurement_5의 결측 여부만 남깁니다.\n",
    "df_train[['na_1', 'na_2']] = df_train[['measurement_3', 'measurement_5']].isna()\n",
    "df_test[['na_1', 'na_2']] = df_test[['measurement_3', 'measurement_5']].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c5d5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C    5765\n",
       "E    5343\n",
       "B    5250\n",
       "A    5100\n",
       "Name: product_code, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['product_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9900034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D    5112\n",
       "Name: product_code, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['product_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1740e2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer# 구문을 사용하여 실험 단계인 모듈을 활성화하고, \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "X_imp = ['measurement_{}'.format(i) for i in range(3, 10)] + ['measurement_17']\n",
    "# train에 등장하지 않은 수준이 있습니다, test를 포함하여 결측처리 모델을 만듭니다.\n",
    "s_imp = pd.concat([\n",
    "                df_train[X_imp + ['product_code']],\n",
    "                df_test[X_imp + ['product_code']]\n",
    "        ], axis=0).groupby('product_code')\\\n",
    "        .apply(\n",
    "            lambda x: IterativeImputer(estimator=LinearRegression(),random_state=123).fit(x[X_imp])\n",
    "        )\n",
    "# train에 적용합니다.\n",
    "df_train[X_imp] = df_train[X_imp + ['product_code']]\\\n",
    "            .groupby('product_code')\\\n",
    "            .apply(\n",
    "                lambda x: pd.DataFrame(s_imp.loc[x.name].transform(x[X_imp]), index=x.index, columns=X_imp)\n",
    "            )\n",
    "# test에 적용합니다.\n",
    "df_test[X_imp] = df_test[X_imp + ['product_code']]\\\n",
    "            .groupby('product_code')\\\n",
    "            .apply(\n",
    "                lambda x: pd.DataFrame(s_imp.loc[x.name].transform(x[X_imp]), index=x.index, columns=X_imp)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026bfbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = ['measurement_{}'.format(i) for i in range(10, 17)]\n",
    "# 역시 train에 등장하지 않은 수준을 처리하기 위해 합치니다.\n",
    "df_mean = pd.concat([\n",
    "            df_train[['product_code'] + X_mean],\n",
    "            df_test[['product_code'] + X_mean]\n",
    "        ]).groupby('product_code')[X_mean].agg('mean')\n",
    "\n",
    "df_train[X_mean] = df_train.groupby('product_code')[X_mean]\\\n",
    "            .apply(lambda x: pd.DataFrame(x.fillna(df_mean.loc[x.name]), index=x.index, columns=x.columns))\n",
    "df_test[X_mean] = df_test.groupby('product_code')[X_mean]\\\n",
    "            .apply(lambda x: pd.DataFrame(x.fillna(df_mean.loc[x.name]), index=x.index, columns=x.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8a0df4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['loading'] = df_train['loading'].fillna(df_train['loading'].mean())\n",
    "# loading은 train에서의 평균으로 결측치를 처리합니다.\n",
    "df_test['loading'] = df_test['loading'].fillna(df_train['loading'].mean())\n",
    "df_train.isna().sum().sum(), df_test.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8966d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공통으로 사용할 만한 요소입니다.\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True) # 5겹의 층화교차검증을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e534cec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.57912402, 0.58968448, 0.57221316, 0.61180378, 0.57922945]),\n",
       " 0.5864109791862437)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline 모델을 만들어봅니다.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# loading, measurment_0~18까지 표준화합니다.\n",
    "# na_1, na_2는 통과시킵니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading'] + ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['na_1', 'na_2'])\n",
    "])\n",
    "\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_lr = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "# Baseline 모델의 성능을 평가합니다.\n",
    "scores = cross_val_score(clf_lr, df_train[X_lr], df_train['failure'], scoring='roc_auc', cv=cv)\n",
    "scores, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "631b2856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('std',\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True),\n",
       "                                                  ['loading', 'measurement_0',\n",
       "                                                   'measurement_1',\n",
       "                                                   'measurement_2',\n",
       "                                                   'measurement_3',\n",
       "                                                   'measurement_4',\n",
       "                                                   'measurement_5',\n",
       "                                                   'measurement_6',\n",
       "                                                   'measurem...\n",
       "                                                   'measurement_16',\n",
       "                                                   'measurement_17']),\n",
       "                                                 ('pt', 'passthrough',\n",
       "                                                  ['na_1', 'na_2'])],\n",
       "                                   verbose=False)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제출을 위한 모델을 만듭니다.\n",
    "clf_lr.fit(df_train[X_lr], df_train['failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5075505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일을 만듭니다.\n",
    "pd.DataFrame(\n",
    "    clf_lr.predict_proba(df_test[X_lr])[:, 1], # failure=1인 확률을 뽑아냅니다.\n",
    "    index=df_test.index\n",
    ").to_csv('answer6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "912de064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채점을 해봅니다.\n",
    "df_ans = pd.read_csv('test_prob_ans.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67d34b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5891265737410073"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(df_ans['failure'], clf_lr.predict_proba(df_test[X_lr])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "238fe5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python37\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# 문제에서 속성 선택법에 대한 힌트가 없을 때를 가정하고 \n",
    "# 빠르게 속성선택법의 효과성을 살펴 봅니다.\n",
    "\n",
    "# 속성선택기 설정을 합니다.\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cv = StratifiedKFold(n_splits=5, random_state=123, shuffle=True) # 5겹 층화교차검증(5-Fold stratified cross validation)\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator = LogisticRegression(solver='lbfgs'),\n",
    "    k_features='best',# 최적의 성능을 보이는 입력 변수의 조합을 찾는다. \n",
    "    forward=True, # 전진 선택\n",
    "    floating=False, # 선택했던 변수를 제외하지 않는다. \n",
    "    cv = cv,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=4 # 좀 더 빨리 뽑아오기 위해 동시 실행을 4로 잡습니다.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f44529a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.57899225, 0.59057654, 0.5762483 , 0.60776799, 0.58230052]),\n",
       " 0.5871771208338508)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(),  ['loading'] + ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['na_1', 'na_2'])\n",
    "])\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "# 속성 선택기를 pipeline 중간에 넣습니다.\n",
    "clf_lr = make_pipeline(ct, sfs, LogisticRegression(solver='lbfgs'))\n",
    "scores = cross_val_score(clf_lr, df_train[X_lr], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "scores, np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dcca7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('std',\n",
       "                                                  StandardScaler(copy=True,\n",
       "                                                                 with_mean=True,\n",
       "                                                                 with_std=True),\n",
       "                                                  ['loading', 'measurement_0',\n",
       "                                                   'measurement_1',\n",
       "                                                   'measurement_2',\n",
       "                                                   'measurement_3',\n",
       "                                                   'measurement_4',\n",
       "                                                   'measurement_5',\n",
       "                                                   'measurement_6',\n",
       "                                                   'measurem...\n",
       "                                           k_features='best', n_jobs=4,\n",
       "                                           pre_dispatch='2*n_jobs',\n",
       "                                           scoring='roc_auc', verbose=0)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 train 셋으로 학습시킵니다.\n",
    "clf_lr.fit(df_train[X_lr], df_train['failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78d5e3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0', '2', '5', '10', '15', '18', '19')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 속성 선택기가 도출한 입력을 봅니다, ColumnTransformer를 거쳐 변수명이 추상화됐습니다.\n",
    "clf_lr[1].k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32445ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58366693, 0.59268903, 0.5654862 , 0.59334217, 0.57527332]),\n",
       " 0.5820915301430556)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# ColumnTransformer에 PCA 파이프라인들 구상했습니다.\n",
    "# 이러한 중첩된 구성 또한 성립합니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('pca', make_pipeline(StandardScaler(), PCA(n_components=7)), ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough',  ['loading'] + ['na_1', 'na_2'])\n",
    "])\n",
    "# GridSearchCV 모델로 구성해봅니다.\n",
    "gscv = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=123),\n",
    "    param_grid={\n",
    "        'n_estimators': [5, 10, 15],\n",
    "        'max_depth': [5, 6, 7],\n",
    "        'min_samples_split': [256, 512]\n",
    "    },\n",
    "    scoring='roc_auc',\n",
    "    iid=False,\n",
    "    cv=StratifiedKFold(n_splits=5, random_state=123, shuffle=True),\n",
    "    n_jobs=4\n",
    ")\n",
    "X_gscv = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_gscv_rf = make_pipeline(ct, gscv)\n",
    "scores_ = cross_val_score(clf_gscv_rf, df_train[X_gscv], df_train['failure'], scoring='roc_auc', cv=cv)\n",
    "scores_, np.mean(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3ab13ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('pca',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('standardscaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with_mean=True,\n",
       "                                                                                  with_std=True)),\n",
       "                                                                  ('pca',\n",
       "                                                                   PCA(copy=True,\n",
       "                                                                       iterated_power='auto',\n",
       "                                                                       n_components=7,\n",
       "                                                                       random_state=None,\n",
       "                                                                       svd_solve...\n",
       "                                                               min_samples_split=2,\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators='warn',\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=123,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False),\n",
       "                              iid=False, n_jobs=4,\n",
       "                              param_grid={'max_depth': [5, 6, 7],\n",
       "                                          'min_samples_split': [256, 512],\n",
       "                                          'n_estimators': [5, 10, 15]},\n",
       "                              pre_dispatch='2*n_jobs', refit=True,\n",
       "                              return_train_score=False, scoring='roc_auc',\n",
       "                              verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 데이터셋에 대한 학습을 합니다.\n",
    "clf_gscv_rf.fit(df_train[X_gscv], df_train['failure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5aeb455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6, 'min_samples_split': 512, 'n_estimators': 15}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결과 hyper-parameter를 봅니다.\n",
    "clf_gscv_rf[1].best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4edd417",
   "metadata": {},
   "source": [
    "# 다른 모델들도 만들어 봅니다. \n",
    "\n",
    "참고삼아 만들어 봣습니다.\n",
    "그리고, 이들을 마지막 앙상블 모델에 넣어 보겟습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7a503b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.59016944, 0.59366441, 0.57107023, 0.59631159, 0.57999249]),\n",
       " 0.586241632091449)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GradientBoosting 모델을 만들어 봅니다.\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "X_gb = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct_3 = ColumnTransformer([\n",
    "    ('pt', 'passthrough', X_gb)\n",
    "])\n",
    "clf_gb = make_pipeline(ct_3, GradientBoostingClassifier(\n",
    "    n_estimators=100, max_depth=2, learning_rate=0.01, random_state=123\n",
    "))\n",
    "scores_ = cross_val_score(clf_gb, df_train[X_gb], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "scores_, np.mean(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8850220f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58362268, 0.5903637 , 0.56514573, 0.59496567, 0.57666012]),\n",
       " 0.5821515804775613)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RandomForestClassifier 모델도 만들어 봅니다. (좀더 튜닝했습니다.)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_rf = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct_4 = ColumnTransformer([\n",
    "    ('std_pca', make_pipeline(StandardScaler(), PCA(n_components=7)), ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['loading', 'na_1', 'na_2'])\n",
    "])\n",
    "clf_rf = make_pipeline(ct_4, RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=7, min_samples_split= 512, random_state=123\n",
    "))\n",
    "scores_ = cross_val_score(clf_rf, df_train[X_rf], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "scores_, np.mean(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5b0c7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58961081, 0.59397   , 0.5726996 , 0.59593267, 0.57998353]),\n",
       " 0.5864393237715635)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgb로 모델을 만들어 봅니다.\n",
    "import xgboost as xgb\n",
    "X_xgb = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct_5 = ColumnTransformer([\n",
    "    ('pt', 'passthrough', X_xgb)\n",
    "])\n",
    "clf_xgb = make_pipeline(ct_3, xgb.XGBClassifier(\n",
    "    n_estimators=150, max_depth=2, learning_rate=0.01, random_state=123\n",
    "))\n",
    "scores_ = cross_val_score(clf_xgb, df_train[X_xgb], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "scores_, np.mean(scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbded5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading'] + ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['na_1', 'na_2'])\n",
    "])\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_lr = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "# 속성 선택 + LogisticRegression 모델입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17']),\n",
    "    ('pt', 'passthrough', ['na_1'])\n",
    "])\n",
    "X_lr = ['loading', 'measurement_1', 'measurement_4', 'measurement_14', 'measurement_17', 'na_1']\n",
    "clf_lr_2 = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "# PCA + LogisticRegression 모델입니다.\n",
    "ct = ColumnTransformer([\n",
    "    ('std', StandardScaler(), ['loading']),\n",
    "    ('std_pca', make_pipeline(StandardScaler(), PCA(n_components=7)) , ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['na_1', 'na_2'])\n",
    "])\n",
    "X_lr = ['loading'] + ['measurement_{}'.format(i) for i in range(18)] + ['na_1', 'na_2']\n",
    "clf_lr_3 = make_pipeline(ct, LogisticRegression(solver='lbfgs'))\n",
    "\n",
    "# GradientBoosting 모델입니다.\n",
    "X_gb = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct = ColumnTransformer([\n",
    "    ('pt', 'passthrough', X_gb)\n",
    "])\n",
    "clf_gb = make_pipeline(ct, GradientBoostingClassifier(\n",
    "    n_estimators=100, max_depth=2, learning_rate=0.01, random_state=123\n",
    "))\n",
    "\n",
    "# Random Forest 입니다.\n",
    "X_rf = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct = ColumnTransformer([\n",
    "    ('std_pca', make_pipeline(StandardScaler(), PCA(n_components=7)), ['measurement_{}'.format(i) for i in range(18)]),\n",
    "    ('pt', 'passthrough', ['loading', 'na_1', 'na_2'])\n",
    "])\n",
    "clf_rf = make_pipeline(ct, RandomForestClassifier(\n",
    "    n_estimators=100, max_depth=7, min_samples_split= 512, random_state=123\n",
    "))\n",
    "\n",
    "# XGBoost 입니다.\n",
    "X_xgb = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)]\n",
    "ct = ColumnTransformer([\n",
    "    ('pt', 'passthrough', X_xgb)\n",
    "])\n",
    "clf_xgb = make_pipeline(ct, xgb.XGBClassifier(\n",
    "    n_estimators=150, max_depth=2, learning_rate=0.01, random_state=123\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b50b43f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.58740394, 0.59446078, 0.57334307, 0.60939866, 0.58233571]),\n",
       " 0.5893884319103216)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "X_vt = ['loading', 'na_1', 'na_2'] + ['measurement_{}'.format(i) for i in range(18)] \n",
    "# 모두 앙상블을 해봅니다. roc_auc에서 확률을 활용하므로 voting 을 soft로 합니다.\n",
    "clf_vt = VotingClassifier(\n",
    "    [\n",
    "        ('lr', clf_lr), #  Baseline\n",
    "        ('lr_2', clf_lr_2), # 속성 선택을 통한 모델\n",
    "        ('lr_3', clf_lr_3), # PCA + 속성 선택 모델 \n",
    "        ('gb', clf_gb), # GradientBoost\n",
    "        ('rf', clf_rf), # Random Forest\n",
    "        ('xgb', clf_xgb) # xgboost\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "scores_ = cross_val_score(clf_vt, df_train[X_vt], df_train['failure'], cv=cv, scoring='roc_auc')\n",
    "score = np.mean(scores_)\n",
    "scores_, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3a7fa79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5928660071942446"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 전체 train에 대해 만들고, 채점도 해봅니다.\n",
    "clf_vt.fit(df_train[X_lr], df_train['failure'])\n",
    "roc_auc_score(df_ans['failure'], clf_vt.predict_proba(df_test[X_lr])[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35c1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
